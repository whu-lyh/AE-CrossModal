
'''tform = input_transform()
img_path = '/datassd4t/zhipengz/mydataset/train_val/s03/database/images/959ddddddd.png'
def save_img_my(tensor, name):
    tensor = tensor.permute((1, 0, 2, 3))
    im = make_grid(tensor, normalize=True, scale_each=True, nrow=8, padding=0).permute((1, 2, 0))
    im = (im.data.numpy() * 255.).astype(np.uint8)
    Image.fromarray(im).save(name + '.png')
def model_test(img_path, model):
    print('model')
    print(model)
    query = tform(Image.open(img_path))
    input_data = query.unsqueeze(0)
    model.eval()
    with torch.no_grad():
        input_data = input_data.to(device)
        image_encoding = model.encoder(input_data)
        print('image_encoding.shape')
        print(image_encoding.shape)
        print('image_encoding')
        print(image_encoding)

        vlad_encoding, v_t = model.pool(image_encoding)
        print('vlad_encoding.shape')
        print(vlad_encoding.shape)
        print('v_t.shape')
        print(v_t.shape)
        print('vlad_encoding')
        print(vlad_encoding)
        print('v_t')
        print(v_t)
    save_img_my(image_encoding.cpu(), 'encoding')
    # vlad_encoding = vlad_encoding.view(-1, 16, 16).unsqueeze(0)
    vlad_encoding = vlad_encoding[0].view(16, 16)
    v_t = v_t.unsqueeze(0)
    save_img_my(v_t.cpu(), 'v_t')
def model3d_test(model3d):
    pc_path = '/datassd4t/zhipengz/dataset_exam3d/mydataset/kitti360/s03/database/pc/0000000145.bin'
    query3d = torch.tensor(load_pc_files([pc_path]))
    input_data = query3d.unsqueeze(0)  # torch.Size([1, 1, 4096, 3])
    print('input.size')
    print(input_data.shape)
    print('model3d')
    print(model3d)
    model3d.eval()
    with torch.no_grad():
        input_data = input_data.to(device)
        pc_encoding = model3d.point_net(input_data)  # torch.Size([1, 1024, 4096, 1])
        print('pc_encoding.shape')
        print(pc_encoding.shape)
        print('pc_encoding')
        print(pc_encoding)

        vlad_encoding = model3d.net_vlad(pc_encoding)  # torch.Size([1, 256])
        print('vlad_encoding.shape')
        print(vlad_encoding.shape)
        # print('v_t.shape')
        # print(v_t.shape)
        print('vlad_encoding')
        print(vlad_encoding)
        # print('v_t')
        # print(v_t)
    save_img_my(pc_encoding.view(1, 1024, 64, 64).cpu(), 'enc_pc')
    vlad_encoding = vlad_encoding.view(1, 16, 16).unsqueeze(0)
    save_img_my(vlad_encoding.cpu(), 'vlad_pc')
def encoder_test():
    model = encoder
    print('model')
    print(model)
    query = tform(Image.open(img_path))
    input_data = query.unsqueeze(0)
    model = model.to(device)
    model.eval()
    with torch.no_grad():
        input_data = input_data.to(device)
        image_encoding = model(input_data)
        print('image_encoding.shape')
        print(image_encoding.shape)
        # print('image_encoding')
        # print(image_encoding)
    save_img_my(image_encoding.cpu(), 'encoding')'''